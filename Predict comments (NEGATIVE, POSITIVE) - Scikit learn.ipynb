{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85935651",
   "metadata": {},
   "source": [
    "# Create a class to easily acces text, and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56f9e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review: #we create a class, Review(text, score)\n",
    "    def __init__(self, text, score): # it means that we can designate values to text and score\n",
    "        self.text = text # Review(text, score).text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment() \n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <=2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #score 4 or 5\n",
    "            return Sentiment.POSITIVE\n",
    "        \n",
    "class ReviewContainer: # ReviewContainer(reviews)\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "        \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews] # we get the list of text from reviews list\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews] # we get the sentiment from reviews list\n",
    "        \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        positive_shrunk = positive[:len(negative)] # say we have 450 negatives and 600 positives. We only select the 450 positives\n",
    "        self.reviews = negative + positive_shrunk # our new reviews length. using the above example, we have 450 negatives + 450 positives which was shrunk\n",
    "        random.shuffle(self.reviews) # after that we shuffle the list to get random positive and random negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e2fbb3",
   "metadata": {},
   "source": [
    "# Import data and append it into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffccba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "I hoped for Mia to have some peace in this book, but her story is so real and raw.  Broken World was so touching and emotional because you go from Mia's trauma to her trying to cope.  I love the way the story displays how there is no \"just bouncing back\" from being sexually assaulted.  Mia showed us how those demons come for you every day and how sometimes they best you. I was so in the moment with Broken World and hurt with Mia because she was surrounded by people but so alone and I understood her feelings.  I found myself wishing I could give her some of my courage and strength or even just to be there for her.  Thank you Lizzy for putting a great character's voice on a strong subject and making it so that other peoples story may be heard through Mia's.\n",
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "file_name = 'C:/Users/Randy/Downloads/archive/Books_small_10000.json'\n",
    "\n",
    "reviews = []\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall'])) # Review(text, score), we designate a value to each variable so...\n",
    "\n",
    "print(reviews[5].score) # when we called on score, it prints the score\n",
    "print(reviews[5].text)\n",
    "print(reviews[5].get_sentiment()) # same with the code below\n",
    "reviews[5].sentiment # same with the code above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3868f624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[5].sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa7a90cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e379a",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c6c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(reviews, test_size=0.33, random_state=42)\n",
    "\n",
    "train_container = ReviewContainer(train)\n",
    "test_container = ReviewContainer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c7165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b26fa70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test) # x variable of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5ddd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "print(train[0].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06988318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 872, 872\n",
      "Test data: 416, 416\n"
     ]
    }
   ],
   "source": [
    "train_container.evenly_distribute() # from the function we created, this splits the review list into equal numbers of POSITIVE AND NEGATIVE\n",
    "\n",
    "train_x = train_container.get_text() # from the train data, we get the text\n",
    "train_y = train_container.get_sentiment() # from the train data, we get the sentiments\n",
    "\n",
    "test_container.evenly_distribute()\n",
    "\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(\"Train data: {x}, {y}\".format(x = len(train_x) , y = len(train_y)))\n",
    "print(\"Test data: {0}, {1}\".format(len(test_x) , len(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69c1c17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6700"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train) # x variable of train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce6f155",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0654aeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love Isa Chandra Moskowitz and Terry Hope Romero, I think they&#8217;re wonderfully creative and imaginative cooks. I own all of their books, and most of those books I use regularly, but I have to say Veganomicon is not one that I use often. Simply put I don&#8217;t love it, and it&#8217;s not because the recipes aren&#8217;t good - virtually all of the ones I&#8217;ve made so far have been stellar -  my biggest complaint is the layout. I hate it, The pages of this book are busy to the point of overflowing with ingredients, instructions and tips. Don&#8217;t get me wrong I have no qualm with long ingredient lists, and I love the helpful tips but each page has at least 2 recipes on it. I hate the way the recipes are split over more then one page as this can make it difficult when actually trying to follow the recipe in the kitchen. It may seem silly, but this really is the sole reason that I rarely use the book. If it had a better layout I&#8217;d probably use it a lot more. Other negative points that some people may be interested in are there is a real lack of photos in the book - just a color photo insert in the center - and there is no nutritional information listed for the recipes. Also some of the recipes seem needlessly long or overly complicated with several time consuming steps.Having said that there are a lot of positives about the book as well. For one it&#8217;s a tome, massive, and filled to the brim with tasty recipes for appetizers, soups, salads, dressings, sauces, proteins, one-pot meals, casseroles, grains, vegetable side dishes, and desserts. There&#8217;s also a large section in the front of the book that details basic cooking techniques, how to fill your vegan pantry, what utensils and cooking equipment is best and general tips on prepping and cooking various vegetables, grains etc... As I said early most recipes also include an additional hint about an ingredient, a cooking method, or what else can be done with the finished product. I got my copy of Veganomicon in 2010 when I was relatively new to veganism and I did find much of this information very helpful. Moskowitz and Romero also make cooking seem effortless, they have a really easy-going down to earth writing style that I appreciate, and I love their sense of humor. I also really appriciate their emphasis on whole foods rather then processed foods. They include a few recipes for making your own seitan, tofu mayo, and other vegan staples.Unfortunately though many of the dishes sound delicious I haven&#8217;t cooked as many recipes from this book that I&#8217;d like. Of the ones I have tried here&#8217;s what I thought...Spicy Tempeh Nori Rolls - Loved it!Grilled Yuca Tortillas - Loved it!Butternut Squash and Pumpkin Seed Rice Paper Rolls - Loved itSamosa Stuffed Baked Potatoes - Loved itCurried Carrot Dip - Loved itWalnut Mushroom Pate - Loved itMediterranean-Style Cashew-Cucumber Dip - Loved it, this is seriously the best Tzatziki dip I&#8217;ve had vegan or otherwise. A definite Go-To recipe for me.Asparagus Spinach Dip - Loved itChocolate Chip Brownie Waffles - Pretty goodBlueberry Corn Pancakes - Loved itAutumn Root Salad with Warm Maple Fig Dressing - Pretty goodCreamy Asian Pear and Tempeh Salad with Wasabi Dressing - Hated it!  Totally inedible.Maple-Mustard Dressing - Loved itSnobby Joes - Loved itChili Cornmeal Crusted Tofu Po&#8217;Boys - Loved itSauteed Spinach and Tomatoes - Loved itBroccoli Polenta - Just okay.Chili Cornmeal Crusted Tofu - Loved itMarinated Asian Tofu - Loved itChickpea Cutlets - Just okayTomato Rice Soup with Roasted Garlic and Navy Beans - Pretty GoodPotato and Kale Enchiladas with Roasted Chili Sauce - Loved itEggplant-Potato Moussaka with Pine Nut Crema - Loved itTempeh Shepherdess Pie - OkayManzana Chili Verde - Loved itLeek and Bean Cassoulet with Biscuits - Loved itPumpkin Saag - Just okaySpicy Tempeh and Broccoli Rabe with Rotelle - Loved itPasta e Fagioli- Loved itPumpkin Baked Ziti with Caramelized onions and Sage Crumb Topping - Pretty goodGreen Pea and Lemon Risotto with Roasted Red Peppers - Loved itSkillet Cornbread - Loved itBanana Wheat Germ Muffins - Loved itCarrot Pineapple Sunshine Muffins - Loved itPistachio Rosewater Cookies - Loved itChocolate Chocolate Chip Walnut Cookies - Loved itPeanut Ginger Sesame Cookies - Loved itFudgy Wudgy Blueberry Brownies - AMAZING!Coconut Lemon Bundt Cake - Loved itOverall the recipes have been really great, and if the book had a better layout I&#8217;d probably be more inclined to use it more frequently. As is this probably wouldn&#8217;t be the first book I&#8217;d recommend to a newbie vegan, but I think a lot of seasoned vegans would really enjoy this book, especially for it&#8217;s creativity - provided of course they don&#8217;t hate the layout as much as I do.\n",
      "  (0, 4782)\t4\n",
      "  (0, 4265)\t1\n",
      "  (0, 1348)\t1\n",
      "  (0, 5194)\t2\n",
      "  (0, 423)\t26\n",
      "  (0, 7905)\t1\n",
      "  (0, 3856)\t1\n",
      "  (0, 6750)\t2\n",
      "  (0, 7968)\t2\n",
      "  (0, 7956)\t4\n",
      "  (0, 115)\t19\n",
      "  (0, 6384)\t1\n",
      "  (0, 8782)\t1\n",
      "  (0, 1842)\t1\n",
      "  (0, 3997)\t1\n",
      "  (0, 1757)\t1\n",
      "  (0, 5637)\t2\n",
      "  (0, 347)\t2\n",
      "  (0, 5478)\t16\n",
      "  (0, 7935)\t3\n",
      "  (0, 996)\t2\n",
      "  (0, 5196)\t2\n",
      "  (0, 7984)\t1\n",
      "  (0, 8428)\t5\n",
      "  (0, 6493)\t1\n",
      "  :\t:\n",
      "  (0, 4292)\t1\n",
      "  (0, 8848)\t1\n",
      "  (0, 962)\t1\n",
      "  (0, 1112)\t1\n",
      "  (0, 392)\t1\n",
      "  (0, 1525)\t1\n",
      "  (0, 1154)\t1\n",
      "  (0, 1189)\t1\n",
      "  (0, 4297)\t1\n",
      "  (0, 3495)\t1\n",
      "  (0, 4043)\t1\n",
      "  (0, 3246)\t1\n",
      "  (0, 8824)\t1\n",
      "  (0, 3087)\t1\n",
      "  (0, 6441)\t1\n",
      "  (0, 5355)\t1\n",
      "  (0, 6937)\t1\n",
      "  (0, 8471)\t1\n",
      "  (0, 8823)\t1\n",
      "  (0, 2686)\t1\n",
      "  (0, 2760)\t1\n",
      "  (0, 1843)\t1\n",
      "  (0, 6236)\t1\n",
      "  (0, 1805)\t1\n",
      "  (0, 2355)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer() # calls and designate a name to the function\n",
    "X_train_vectors = vectorizer.fit_transform(train_x) # fits (make a model) and transforms (scales it) train x data - Vectorized train x data\n",
    "\n",
    "X_test_vectors = vectorizer.transform(test_x) # transforms test x (we do not fit it as it will not be used as a model)\n",
    "\n",
    "\n",
    "print(train_x[0])\n",
    "print(X_train_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c35b0b",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d165650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I chose this rating because it was true!  The Scottish Prisoner was a perfect accompaniment to the main series.  Everything fit perfectly. All of the little details matched.I so enjoy Diana Gabaldon's books.  I am eagerly awaiting the next book in the main series due out this year, 2014.  So much so that I pre-ordered it!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear') # create an SVM regressor\n",
    "clf_svm.fit(X_train_vectors, train_y) # Fits the X_train_vectors to train_y using SVM\n",
    "\n",
    "# Model\n",
    "print(test_x[0])\n",
    "clf_svm.predict(X_test_vectors[0]) # Uses the model we created to predict a Vectorized test x data\n",
    "\n",
    "# Below, we see that the first element in the test x data has a text. The model predicts whether that text is positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74da6c88",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b3869b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I chose this rating because it was true!  The Scottish Prisoner was a perfect accompaniment to the main series.  Everything fit perfectly. All of the little details matched.I so enjoy Diana Gabaldon's books.  I am eagerly awaiting the next book in the main series due out this year, 2014.  So much so that I pre-ordered it!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dec_tree = DecisionTreeClassifier() \n",
    "clf_dec_tree.fit(X_train_vectors, train_y) # fit X_train_vectors to train_y\n",
    "\n",
    "\n",
    "print(test_x[0])\n",
    "clf_dec_tree.predict(X_test_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aebecf",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22bd270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseTransformer(): # Makes X dense using toarray() function\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a995cd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I chose this rating because it was true!  The Scottish Prisoner was a perfect accompaniment to the main series.  Everything fit perfectly. All of the little details matched.I so enjoy Diana Gabaldon's books.  I am eagerly awaiting the next book in the main series due out this year, 2014.  So much so that I pre-ordered it!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline # we use pipeline and store all functions inside of it\n",
    "\n",
    "pipeline = Pipeline([('to_dense', DenseTransformer()), ('classifier', GaussianNB())])\n",
    "\n",
    "pipeline.fit(X_train_vectors, train_y)\n",
    "\n",
    "print(test_x[0])\n",
    "pipeline.predict(X_test_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94b98e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I chose this rating because it was true!  The Scottish Prisoner was a perfect accompaniment to the main series.  Everything fit perfectly. All of the little details matched.I so enjoy Diana Gabaldon's books.  I am eagerly awaiting the next book in the main series due out this year, 2014.  So much so that I pre-ordered it!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(X_train_vectors, train_y)\n",
    "\n",
    "print(test_x[0])\n",
    "clf_log.predict(X_test_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ec6b3",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83a45447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6538461538461539\n",
      "0.6346153846153846\n",
      "0.7980769230769231\n",
      "0.8149038461538461\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "\n",
    "print(clf_dec_tree.score(X_test_vectors, test_y))\n",
    "print(pipeline.score(X_test_vectors, test_y))\n",
    "print(clf_svm.score(X_test_vectors, test_y))\n",
    "print(clf_log.score(X_test_vectors, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d06a696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8028169  0.79310345 0.        ]\n",
      "[0.82051282 0.808933   0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Randy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Randy\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "# F1 Score, Confusion Matrix (Sensitivity, Specificity, % of correctly predicting TRUE NEUTRALS)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(test_y, clf_svm.predict(X_test_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE, Sentiment.NEUTRAL]))\n",
    "print(f1_score(test_y, clf_log.predict(X_test_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE, Sentiment.NEUTRAL]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0889829d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.count(Sentiment.NEGATIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5cf83ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_y.count(Sentiment.NEGATIVE))\n",
    "train_y.count(Sentiment.POSITIVE)# we have 670 train labels, 552 are positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b2b02",
   "metadata": {},
   "source": [
    "# Balance Positives and Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ece8acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what we have found out in our model is that it is heavily biased on predicting TRUE POSITIVES. Thus we load in more raw data\n",
    "# Since adding raw data did nothing significant, we also equally splitted the counts of negative and positive, both on test and train data\n",
    "# besides vectorizer, we can use tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07584efe",
   "metadata": {},
   "source": [
    "# Testing out the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc65a8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a comment: The book was very good. I loved every detail of it. Will read it again\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prototype_data = [input(\"Enter a comment: \")]\n",
    "new_test = vectorizer.transform(prototype_data)\n",
    "\n",
    "clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec508ca",
   "metadata": {},
   "source": [
    "# Saving our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "c7881567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('C:/Users/Randy/Downloads/IE things/ML Models/Sentiment_Classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_svm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d47956",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "a8b9478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/Randy/Downloads/IE things/ML Models/Sentiment_Classifier.pkl', 'rb') as f:\n",
    "    loaded_clf_svm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "3b99f404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a comment: It was mediocre\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads the model again\n",
    "\n",
    "prototype_data = [input(\"Enter a comment: \")]\n",
    "new_test = vectorizer.transform(prototype_data)\n",
    "\n",
    "loaded_clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827069fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
